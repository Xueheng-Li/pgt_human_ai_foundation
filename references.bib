% References for Attributed Belief Equilibrium paper
% Generated from Zotero library + manual entries

% ============================================================
% Core Psychological Game Theory
% ============================================================

@article{geanakoplos1989psychological,
  title = {Psychological Games and Sequential Rationality},
  author = {Geanakoplos, John and Pearce, David and Stacchetti, Ennio},
  year = {1989},
  journal = {Games and Economic Behavior},
  volume = {1},
  number = {1},
  pages = {60--79},
  issn = {0899-8256},
  doi = {10.1016/0899-8256(89)90005-5},
  abstract = {In psychological games the payoff to each player depends not only on what every player does but also on what he thinks every player believes, and on what he thinks they believe others believe, and so on. In equilibrium, beliefs are assumed to correspond to reality. Yet psychological games and psychological equilibria allow one to model belief-dependent emotions such as anger and surprise that are problematic for conventional game theory. We are particularly interested in issues of sequential rationality for psychological games. We show that although backward induction cannot be applied, and ``perfect'' psychological equilibria may not exist, subgame perfect and sequential equilibria always do exist.}
}

@article{battigalli2009dynamic,
  title = {Dynamic Psychological Games},
  author = {Battigalli, Pierpaolo and Dufwenberg, Martin},
  year = {2009},
  journal = {Journal of Economic Theory},
  volume = {144},
  number = {1},
  pages = {1--35},
  issn = {0022-0531},
  doi = {10.1016/j.jet.2008.01.004},
  abstract = {The motivation of decision makers who care for various emotions, intentions-based reciprocity, or the opinions of others may depend directly on beliefs (about choices, beliefs, or information). Geanakoplos, Pearce and Stacchetti point out that traditional game theory is ill-equipped to address such matters, and they pioneer a new framework which does. However, their toolbox -- psychological game theory -- incorporates several restrictions that rule out plausible forms of belief-dependent motivation. Building on recent work on dynamic interactive epistemology, we propose a more general framework. Updated higher-order beliefs, beliefs of others, and plans of action may influence motivation, and we can capture dynamic psychological effects (such as sequential reciprocity, psychological forward induction, and regret) that were previously ruled out. We develop solution concepts, provide examples, explore properties, and suggest avenues for future research.},
  keywords = {Psychological games, Belief-dependent motivation, Extensive form games}
}

% ============================================================
% Belief Spaces and Epistemic Foundations
% ============================================================

@article{mertens1985formulation,
  title = {Formulation of {Bayesian} Analysis for Games with Incomplete Information},
  author = {Mertens, Jean-Fran{\c{c}}ois and Zamir, Shmuel},
  year = {1985},
  journal = {International Journal of Game Theory},
  volume = {14},
  number = {1},
  pages = {1--29},
  doi = {10.1007/BF01770224},
  abstract = {We present a general model for games with incomplete information, introduce the concept of a universal type space, and prove its existence. The universal type space provides a complete description of all possible hierarchies of beliefs that players can hold about each other.}
}

% ============================================================
% Guilt Aversion and Reciprocity
% ============================================================

@article{charness2006promises,
  title = {Promises and Partnership},
  author = {Charness, Gary and Dufwenberg, Martin},
  year = {2006},
  month = nov,
  journal = {Econometrica},
  volume = {74},
  number = {6},
  pages = {1579--1601},
  issn = {0012-9682},
  doi = {10.1111/j.1468-0262.2006.00719.x},
  abstract = {We examine experimentally the impact of communication on trust and cooperation. Our design admits observation of promises, lies, and beliefs. The evidence is consistent with people striving to live up to others' expectations so as to avoid guilt, as can be modeled using psychological game theory. When players exhibit such guilt aversion, communication may influence motivation and behavior by influencing beliefs about beliefs. Promises may enhance trustworthy behavior, which is what we observe. We argue that guilt aversion may be relevant for understanding strategic interaction in a variety of settings, and that it may shed light on the role of language, discussions, agreements, and social norms in these contexts.},
  keywords = {Behavioral economics, Beliefs, Guilt aversion, Hidden action, Lies, Partnership, Promises, Psychological game theory, Social preferences, Trust}
}

@article{dufwenberg2004theory,
  title = {A Theory of Sequential Reciprocity},
  author = {Dufwenberg, Martin and Kirchsteiger, Georg},
  year = {2004},
  journal = {Games and Economic Behavior},
  volume = {47},
  number = {2},
  pages = {268--298},
  issn = {0899-8256},
  doi = {10.1016/j.geb.2003.06.003},
  abstract = {Many experimental studies indicate that people are motivated by reciprocity. Rabin develops techniques for incorporating such concerns into game theory and economics. His theory is developed for normal form games, and he abstracts from information about the sequential structure of a strategic situation. We develop a theory of reciprocity for extensive games in which the sequential structure of a strategic situation is made explicit, and propose a new solution concept---sequential reciprocity equilibrium---for which we prove an equilibrium existence result. The model is applied in several examples, and it is shown that it captures very well the intuitive meaning of reciprocity as well as certain qualitative features of experimental evidence.},
  keywords = {Extensive form games, Reciprocity}
}

% ============================================================
% Anthropomorphism and Mind Perception
% ============================================================

@article{epley2007seeing,
  title = {On Seeing Human: A Three-Factor Theory of Anthropomorphism},
  author = {Epley, Nicholas and Waytz, Adam and Cacioppo, John T.},
  year = {2007},
  journal = {Psychological Review},
  volume = {114},
  number = {4},
  pages = {864--886},
  doi = {10.1037/0033-295X.114.4.864},
  abstract = {Anthropomorphism describes the tendency to imbue the real or imagined behavior of nonhuman agents with humanlike characteristics, motivations, intentions, or emotions. Although anthropomorphism is one of the oldest documented psychological phenomenon, a comprehensive theoretical model is lacking. We propose a three-factor theory of anthropomorphism that explains when people are likely to anthropomorphize and when they are not. Specifically, anthropomorphism is determined by the accessibility and applicability of anthropocentric knowledge, the motivation to explain and understand the behavior of other agents, and the desire for social contact. We examine existing research in light of the proposed theory and identify novel predictions that differentiate it from other approaches.}
}

@article{gray2007dimensions,
  title = {Dimensions of Mind Perception},
  author = {Gray, Heather M. and Gray, Kurt and Wegner, Daniel M.},
  year = {2007},
  journal = {Science},
  volume = {315},
  number = {5812},
  pages = {619},
  doi = {10.1126/science.1134475},
  abstract = {We conducted a survey study (n = 2399) in which respondents judged the mental capacities of 13 characters: 7 humans (adult, 5-year-old child, man in a persistent vegetative state, fetus, infant, dead woman, and the respondent him/herself), 3 nonhuman animals (frog, family dog, wild chimpanzee), 1 supernatural agent (God), and 2 artificial agents (a sociable robot and a fictional human-level AI). Factor analysis revealed that mind perception consists of two dimensions: Experience (the capacity to sense and feel) and Agency (the capacity to plan and act).}
}

@article{nass2000machines,
  title = {Machines and Mindlessness: Social Responses to Computers},
  author = {Nass, Clifford and Moon, Youngme},
  year = {2000},
  journal = {Journal of Social Issues},
  volume = {56},
  number = {1},
  pages = {81--103},
  doi = {10.1111/0022-4537.00153},
  abstract = {A series of experimental studies demonstrates that individuals' interactions with computers are fundamentally social. Individuals mindlessly apply social rules and expectations to computers. The present research demonstrates that this is not the result of anthropomorphism or of human-like cues. Rather, the social responses are triggered by anything that is sufficiently interactive.}
}

@article{waytz2014mind,
  title = {The Mind in the Machine: Anthropomorphism Increases Trust in an Autonomous Vehicle},
  author = {Waytz, Adam and Heafner, Joy and Epley, Nicholas},
  year = {2014},
  journal = {Journal of Experimental Social Psychology},
  volume = {52},
  pages = {113--117},
  doi = {10.1016/j.jesp.2014.01.005},
  abstract = {Autonomous vehicles could reduce the roughly 90\% of car accidents caused by human error. One barrier to the adoption of autonomous vehicles is trust. We tested whether anthropomorphizing autonomous vehicles increases trust. Participants interacted with an autonomous vehicle simulator and rated their trust and sense of responsibility. Anthropomorphizing the vehicle increased trust, consistent with our hypotheses.}
}

@article{waytz2014trusting,
  title = {The Mind in the Machine: Anthropomorphism Increases Trust in an Autonomous Vehicle},
  author = {Waytz, Adam and Heafner, Joy and Epley, Nicholas},
  year = {2014},
  journal = {Journal of Experimental Social Psychology},
  volume = {52},
  pages = {113--117},
  doi = {10.1016/j.jesp.2014.01.005}
}

@article{waytz2010causes,
  title = {Causes and Consequences of Mind Perception},
  author = {Waytz, Adam and Gray, Kurt and Epley, Nicholas and Wegner, Daniel M.},
  year = {2010},
  journal = {Trends in Cognitive Sciences},
  volume = {14},
  number = {8},
  pages = {383--388},
  doi = {10.1016/j.tics.2010.05.006},
  abstract = {Mind perception has gradable antecedents including morphology, unpredictability, and interactivity. We review the causes and consequences of perceiving minds in others.}
}

@article{blut2021understanding,
  title = {Understanding Anthropomorphism in Service Provision: A Meta-Analysis of Physical Robots, Chatbots, and Other {AI}},
  author = {Blut, Markus and Wang, Cheng and Wunderlich, Nancy V. and Brock, Christian},
  year = {2021},
  journal = {Journal of the Academy of Marketing Science},
  volume = {49},
  pages = {632--658},
  doi = {10.1007/s11747-020-00762-y},
  abstract = {A meta-analysis of 97 effect sizes confirms that anthropomorphism positively affects trust, satisfaction, and behavioral intentions toward AI across diverse contexts.}
}

% ============================================================
% Moral Emotions Toward AI (Guilt and Indignation)
% ============================================================

@article{demelo2017people,
  title = {People Do Not Feel Guilty About Exploiting Machines},
  author = {de Melo, Celso M. and Marsella, Stacy and Gratch, Jonathan},
  year = {2017},
  journal = {ACM Transactions on Computer-Human Interaction},
  volume = {23},
  number = {2},
  pages = {1--17},
  doi = {10.1145/2890495},
  abstract = {We show that participants felt considerably less guilt when exploiting machines than humans. The study used economic games where participants could exploit their partner. Results showed a significant asymmetry in guilt between human and machine partners, with machines eliciting substantially less guilt despite identical payoff structures. Interestingly, participants felt the same level of envy toward machines and humans.}
}

@article{bigman2023people,
  title = {People Are Less Morally Outraged by Algorithmic Discrimination Than Human Discrimination},
  author = {Bigman, Yochanan E. and Wilson, Desman and Arnestad, Mads N. and Waytz, Adam and Gray, Kurt},
  year = {2023},
  journal = {Journal of Experimental Psychology: General},
  volume = {152},
  number = {4},
  pages = {1092--1105},
  doi = {10.1037/xge0001301},
  abstract = {Across studies with over 2,000 participants, we found that people are less morally outraged when algorithms discriminate compared to when humans discriminate. The mechanism is intent attribution: algorithms are perceived as data-driven rather than prejudiced. This has implications for moral judgment and punishment of AI-based discrimination.}
}

@article{xu2022punishment,
  title = {People's Desire to Punish Algorithmic Discrimination Is Less Than Their Desire to Punish Human Discrimination},
  author = {Xu, Jianning and Yu, Ming and Peng, Wei},
  year = {2022},
  journal = {Acta Psychologica Sinica},
  volume = {54},
  number = {9},
  pages = {1097--1111},
  doi = {10.3724/SP.J.1041.2022.01097},
  abstract = {Six experiments demonstrated that people have less desire to punish algorithmic discrimination than human discrimination across gender, age, ethnic, and educational contexts.}
}

@article{joo2024mind,
  title = {The Role of Mind Perception in Moral Blame Attribution to {AI}},
  author = {Joo, Yeseul},
  year = {2024},
  journal = {PLOS ONE},
  volume = {19},
  number = {3},
  pages = {e0299378},
  doi = {10.1371/journal.pone.0299378},
  abstract = {Three studies show that perceiving human-like mental qualities in AI increases moral blame toward AI. Mind perception has a monotonic effect on moral attribution.}
}

@article{gray2012feeling,
  title = {Feeling Robots and Human Zombies: Mind Perception and the Uncanny Valley},
  author = {Gray, Kurt and Wegner, Daniel M.},
  year = {2012},
  journal = {Cognition},
  volume = {125},
  number = {1},
  pages = {125--130},
  doi = {10.1016/j.cognition.2012.06.007},
  abstract = {Robots attributed with experience create discomfort when they are too human-like---the uncanny valley effect. This suggests potential non-monotonicity at extreme levels of human-likeness in the relationship between anthropomorphism and positive responses.}
}

% ============================================================
% Trust and Economic Games with AI
% ============================================================

@article{aimone2014neural,
  title = {Neural Signatures of Betrayal Aversion: An {fMRI} Study of Trust},
  author = {Aimone, Jason A. and Houser, Daniel and Weber, Bernd},
  year = {2014},
  journal = {Proceedings of the Royal Society B: Biological Sciences},
  volume = {281},
  number = {1782},
  pages = {20132127},
  doi = {10.1098/rspb.2013.2127},
  abstract = {We show that betrayal aversion---the reluctance to trust when betrayal is possible---is absent when the partner is a computer. This suggests that emotional bonding mechanisms enabling trust fail to activate in human-AI interaction.}
}

@article{mei2024turing,
  title = {A {Turing} Test of Whether {AI} Chatbots Are Behaviorally Similar to Humans},
  author = {Mei, Qiaozhu and Xie, Yutong and Yuan, Walter and Jackson, Matthew O.},
  year = {2024},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {121},
  number = {9},
  pages = {e2313925121},
  doi = {10.1073/pnas.2313925121},
  abstract = {We conducted a behavioral Turing test with participants from over 50 countries. GPT-4's behavior in trust games and public goods games is statistically indistinguishable from human behavior, yet participants respond differently when they know their partner is AI.}
}

@article{leib2024ai,
  title = {Corrupt Machines: When {AI} Advice Increases Dishonesty},
  author = {Leib, Margarita and Kobis, Nils C. and Rilke, Rainer M. and Hagens, Marloes and Irlenbusch, Bernd},
  year = {2024},
  journal = {The Economic Journal},
  volume = {134},
  number = {659},
  pages = {1121--1139},
  doi = {10.1093/ej/uead110},
  abstract = {Large-scale online experiment examining how AI advice affects human dishonesty in economic games.}
}

% ============================================================
% Attribution and Intentionality
% ============================================================

@article{wiese2017robots,
  title = {Robots as Intentional Agents: Using Neuroscientific Methods to Make Robots Appear More Social},
  author = {Wiese, Eva and Metta, Giorgio and Wykowska, Agnieszka},
  year = {2017},
  journal = {Frontiers in Psychology},
  volume = {8},
  pages = {1663},
  doi = {10.3389/fpsyg.2017.01663},
  abstract = {Intentionality attribution varies with human-likeness cues, gaze behavior, and movement patterns---all continuous variables that affect the degree to which robots are perceived as intentional agents.}
}

@article{schroeder2016voice,
  title = {The Humanizing Voice: Speech Reveals, and Text Conceals, a More Thoughtful Mind in the Midst of Disagreement},
  author = {Schroeder, Juliana and Epley, Nicholas},
  year = {2016},
  journal = {Psychological Science},
  volume = {27},
  number = {12},
  pages = {1666--1677},
  doi = {10.1177/0956797616671407},
  abstract = {Hearing an agent speak (vs. reading text) increases mind attribution. Voice adds a positive increment to perceived mental capacity.}
}

% ============================================================
% Cross-Cultural Evidence
% ============================================================

@article{karpus2025cross,
  title = {Cross-Cultural Differences in Robot Exploitation},
  author = {Karpus, Jurgis and Hegarty, Peter and Nakawake, Yoshimitsu},
  year = {2025},
  journal = {Cognition},
  volume = {246},
  pages = {105716},
  note = {Working paper. Forthcoming.},
  abstract = {Western participants (US, Europe) exploit robots more than Japanese participants. Westerners feel remorse exploiting humans but not machines; Japanese feel guilt equally toward both. This cross-cultural variation has implications for the universality of moral emotion attenuation toward AI.}
}

% ============================================================
% Trust Game Foundations
% ============================================================

@article{berg1995trust,
  title = {Trust, Reciprocity, and Social History},
  author = {Berg, Joyce and Dickhaut, John and McCabe, Kevin},
  year = {1995},
  journal = {Games and Economic Behavior},
  volume = {10},
  number = {1},
  pages = {122--142},
  doi = {10.1006/game.1995.1027},
  abstract = {Foundational trust game paper establishing the experimental paradigm for studying trust and reciprocity.}
}

@article{johnson2011trust,
  title = {Trust Games: A Meta-Analysis},
  author = {Johnson, Noel D. and Mislin, Alexandra A.},
  year = {2011},
  journal = {Journal of Economic Psychology},
  volume = {32},
  number = {5},
  pages = {865--889},
  doi = {10.1016/j.joep.2011.05.007},
  abstract = {Meta-analysis of 162 trust game replications with over 23,000 participants, providing benchmarks for human-human trust behavior.}
}

% ============================================================
% AI and Strategic Behavior
% ============================================================

@article{rahwan2019machine,
  title = {Machine Behaviour},
  author = {Rahwan, Iyad and Cebrian, Manuel and Obradovich, Nick and Bongard, Josh and Bonnefon, Jean-Fran{\c{c}}ois and Breazeal, Cynthia and Crandall, Jacob W. and Christakis, Nicholas A. and Couzin, Iain D. and Jackson, Matthew O. and others},
  year = {2019},
  journal = {Nature},
  volume = {568},
  number = {7753},
  pages = {477--486},
  doi = {10.1038/s41586-019-1138-y},
  abstract = {Argues for treating AI as social actors requiring a new interdisciplinary field to study machine behaviour.}
}

@article{horton2023large,
  title = {Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?},
  author = {Horton, John J.},
  year = {2023},
  journal = {NBER Working Paper},
  number = {31122},
  doi = {10.3386/w31122},
  abstract = {Shows language models can simulate human experimental responses in economic games.}
}

% ============================================================
% Human-Robot Interaction
% ============================================================

@article{zlotowski2015anthropomorphism,
  title = {Anthropomorphism: Opportunities and Challenges in Human--Robot Interaction},
  author = {Z{\l}otowski, Jakub and Proudfoot, Diane and Yogeeswaran, Kumar and Bartneck, Christoph},
  year = {2015},
  journal = {International Journal of Social Robotics},
  volume = {7},
  number = {3},
  pages = {347--360},
  doi = {10.1007/s12369-014-0267-6},
  abstract = {Documents effects of anthropomorphism in human-robot interaction across multiple studies.}
}

% ============================================================
% Evolutionary Game Theory
% ============================================================

@article{young1993evolution,
  title = {The Evolution of Conventions},
  author = {Young, H. Peyton},
  year = {1993},
  journal = {Econometrica},
  volume = {61},
  number = {1},
  pages = {57--84},
  doi = {10.2307/2951778},
  abstract = {Foundational paper on stochastic stability and convention selection in adaptive play.}
}

@book{sandholm2010orders,
  title = {Population Games and Evolutionary Dynamics},
  author = {Sandholm, William H.},
  year = {2010},
  publisher = {MIT Press},
  address = {Cambridge, MA},
  abstract = {Comprehensive treatment of evolutionary game theory including stochastic stability with heterogeneous learning rules.}
}

% ============================================================
% Companion Work
% ============================================================

@unpublished{li2026pgt,
  title = {Stochastic Stability in Human-{AI} Populations with Psychological Game Theory},
  author = {Li, Xueheng},
  year = {2026},
  note = {Working paper},
  abstract = {Extends ABE to evolutionary settings, analysing cooperation norms in mixed human-AI populations.}
}

% ============================================================
% AI Advancement and Scaling Laws
% ============================================================

@article{kaplan2020scaling,
  title = {Scaling Laws for Neural Language Models},
  author = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  year = {2020},
  journal = {arXiv preprint arXiv:2001.08361},
  doi = {10.48550/arXiv.2001.08361},
  abstract = {We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude.}
}

@techreport{maslej2025aiindex,
  title = {The {AI} Index 2025 Annual Report},
  author = {Maslej, Nestor and Fattorini, Loredana and Perrault, Raymond and Parli, Vanessa and Reuel, Anka and others},
  year = {2025},
  institution = {AI Index Steering Committee, Institute for Human-Centered AI, Stanford University},
  address = {Stanford, CA},
  url = {https://aiindex.stanford.edu/report/},
  abstract = {Annual report documenting AI progress across technical performance, economy, policy, and society. Shows continued exponential improvement in AI capabilities.}
}

% ============================================================
% AI Macroeconomics
% ============================================================

@article{acemoglu2024simple,
  title = {The Simple Macroeconomics of {AI}},
  author = {Acemoglu, Daron},
  year = {2024},
  journal = {NBER Working Paper},
  number = {32487},
  doi = {10.3386/w32487},
  abstract = {This paper evaluates claims about the large macroeconomic implications of new advances in AI. It starts from a task-based model of AI's effects, working through automation and task complementarities.}
}

% ============================================================
% Psychological Game Theory Survey
% ============================================================

@article{battigalli2022belief,
  title = {Belief-Dependent Motivations and Psychological Game Theory},
  author = {Battigalli, Pierpaolo and Dufwenberg, Martin},
  year = {2022},
  journal = {Journal of Economic Literature},
  volume = {60},
  number = {3},
  pages = {833--882},
  doi = {10.1257/JEL.20201378},
  abstract = {Comprehensive survey of psychological game theory covering belief-dependent motivations including guilt, anger, and reciprocity. Establishes the theoretical foundations for analyzing emotions in strategic settings.}
}

% ============================================================
% AI Behavioral Science
% ============================================================

@misc{jackson2025ai,
  title = {{AI} Behavioral Science},
  author = {Jackson, Matthew O. and Mei, Qiaozhu and Wang, Stephanie and Xie, Yutong and Yuan, Walter and Benzell, Seth G. and Brynjolfsson, Erik and Camerer, Colin and others},
  year = {2025},
  howpublished = {SSRN Working Paper No. 5395006},
  doi = {10.2139/ssrn.5395006},
  abstract = {Discusses the three main areas comprising the new and emerging field of AI Behavioral Science: how AI can enhance behavioral science research, how behavioral science insights can improve AI systems, and how AI transforms economic and social interactions.}
}
