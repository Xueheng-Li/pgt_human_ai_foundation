% Proof of Proposition: Welfare Effects of Anthropomorphism
% Appendix material for main manuscript
% Condensed version: 2026-01-14 (numerical example and remarks moved to Online Appendix OA.6.1)

\begin{proof}[Proof of Proposition~\ref{prop:welfare-anthro}]
Two claims. Part 1 requires (A2') attribution monotonicity, (E) cooperation efficiency, and (I) indignation dominance. Part 2 requires (A2') and (G) guilt dominance.

\medskip
\noindent\textbf{Part 1: Higher anthropomorphism weakly increases material welfare when AI is prosocial.}

By Proposition~\ref{prop:public-goods}(i), human $i$ cooperates when the psychological cost of defection exceeds the material gain:
\begin{equation}
    \beta_i \left[ (n_H - 1) + \lambda_i^{IND} n_A \omega_i \bar{h}_H \right] \geq E\left(1 - \frac{m}{n}\right).
\end{equation}
Solving yields threshold $\bar{\omega}_i = [E(1 - m/n) - \beta_i(n_H - 1)] / [\beta_i \lambda_i^{IND} n_A \bar{h}_H]$.

Since $\partial \bar{\omega}_i / \partial \omega_i < 0$ under (A2'), higher $\omega$ makes cooperation easier to sustain. Welfare is $W(s^*) = nE$ under defection and $W(s^*) = nmE$ under cooperation. At threshold crossing, welfare jumps by $n(m-1)E > 0$. Hence $\partial W(s^*) / \partial \omega \geq 0$. \qed

\medskip
\noindent\textbf{Part 2: Higher anthropomorphism may reduce extended welfare when AI is materialist.}

Consider the trust game with materialist AI ($\rho_A = 0$). The zero-anthropomorphism benchmark is $\tilde{h}^{(2,A),ZA} = 0$. A human with $\omega_H > 0$ attributes phantom expectations $\tilde{h}_H^{(2,A)} = \omega_H \cdot 5x > 0$.

Under (G), $y^* = \min\{\tilde{h}_H^{(2,A)}, 3x\}$. When $\tilde{h}_H^{(2,A)} > 3x$:
\begin{equation}
    \psi_H^{GUILT} = -G \cdot (\tilde{h}_H^{(2,A)} - 3x) < 0.
\end{equation}
This guilt is pure welfare loss---phantom expectations have no counterpart in AI preferences.

See Online Appendix OA.6.1 for numerical example demonstrating extended welfare falling from 30 to 0 as $\omega_H$ rises. \qed
\end{proof}

\begin{remark}
Extended analysis including the weak vs.\ strict inequality distinction, asymmetry between parts, and policy implications for AI transparency appears in Online Appendix OA.6.1.
\end{remark}
