% Proof of Proposition: Coordination ABE
% Appendix material for main manuscript
% Condensed version: 2026-01-14 (remarks moved to Online Appendix OA.5.3)

\begin{proof}[Proof of Proposition~\ref{prop:coordination}]
The proposition establishes three claims about coordination games with AI as focal point providers. Required conditions: (A2') Attribution Monotonicity and (C) Signal Clarity ($x_A > 0.5$).

\medskip
\noindent\textbf{Game Setup.}
One human $H$ and one AI $A$, each choosing from $\{A, B\}$. Material payoffs: 2 if coordinated, 0 otherwise. AI has design commitment $\theta_A > 0$ favoring action $A$. Human experiences expectation conformity: $\psi_H(s_H) = -\beta_H \lambda_H^{EC} \sum_{s' \neq s_H} \tilde{h}_H^{(2,A)}(s')$.

Attribution: $\tilde{h}_H^{(2,A)}(A) = \omega_H x_A$ and $\tilde{h}_H^{(2,A)}(B) = \omega_H(1 - x_A)$.

%------------------------------------------------------------------------------
% PART (i)
%------------------------------------------------------------------------------

\medskip
\noindent\textbf{Proof of (i): AI signaling $A$ clearly makes attributed beliefs favour $A$.}

Given AI plays $A$ and signals with $x_A > 0.5$ (condition C):
\begin{equation}
    \tilde{h}_H^{(2,A)}(A) = \omega_H x_A > \omega_H(1 - x_A) = \tilde{h}_H^{(2,A)}(B).
\end{equation}
Attributed beliefs favour $A$. See Online Appendix OA.5.3 for detailed AI utility calculations. \qed

%------------------------------------------------------------------------------
% PART (ii)
%------------------------------------------------------------------------------

\medskip
\noindent\textbf{Proof of (ii): High anthropomorphism amplifies the psychological pull toward the AI-favoured equilibrium.}

Define psychological pull: $\Delta U_H \equiv U_H(A; A) - U_H(B; A)$. Given $s_A = A$:
\begin{align}
    U_H(A; A) &= 2 - \beta_H \lambda_H^{EC} \omega_H(1 - x_A), \\
    U_H(B; A) &= 0 - \beta_H \lambda_H^{EC} \omega_H x_A.
\end{align}

Thus:
\begin{equation}
    \Delta U_H = 2 + \beta_H \lambda_H^{EC} \omega_H (2x_A - 1).
\end{equation}

Comparative static:
\begin{equation}
    \frac{\partial \Delta U_H}{\partial \omega_H} = \beta_H \lambda_H^{EC} (2x_A - 1) > 0 \quad \text{(since } x_A > 0.5\text{)}.
\end{equation}

Higher anthropomorphism increases the utility advantage of playing $A$. \qed

%------------------------------------------------------------------------------
% PART (iii)
%------------------------------------------------------------------------------

\medskip
\noindent\textbf{Proof of (iii): AI can serve as focal point providers, resolving coordination problems.}

\emph{$(A, A)$ is an ABE.} By Part (ii), $\Delta U_H > 0$, so $A$ is the unique best response to $s_A = A$. Given design commitment $\theta_A > 0$, AI optimally plays $A$. All ABE conditions are satisfied.

\emph{$(B, B)$ is not an ABE.} Either $\theta_A > 2$ (AI deviates to $A$) or under binding constraint interpretation, $s_A = B$ violates the AI's programmed behavior.

\emph{Focal point mechanism.} AI resolves multiplicity through: (1) commitment via $\theta_A$; (2) signaling via $x_A > 0.5$; (3) attribution via $\tilde{h}_H^{(2,A)}(A) > \tilde{h}_H^{(2,A)}(B)$; (4) psychological pressure via expectation conformity. \qed
\end{proof}

\begin{remark}
Extended analysis including numerical example, knife-edge case $x_A = 0.5$, contrast with Schelling focal points, and connection to multiplicity appears in Online Appendix OA.5.3.
\end{remark}
