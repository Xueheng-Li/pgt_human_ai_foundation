% Draft Opening Sections - Phase 2
% Section 1: Opening (Motivation and Problem) - ~350 words
% Section 2: Core Innovation (ABE Concept) - ~400 words
% No mathematical notation - verbal descriptions only

%==============================================================================
% SECTION 1: OPENING (MOTIVATION AND PROBLEM)
% Target: 350 words | 2 paragraphs
%==============================================================================

% Paragraph 1: The Challenge (~175 words)
% Emphatic ending: "cannot accommodate this heterogeneity"

Artificial intelligence transforms economic and social life \citep{kaplan2020scaling, maslej2025aiindex}. Humans increasingly interact with AI agents---as collaborators, counterparties, and competitors \citep{acemoglu2024simple, rahwan2019machine}---creating a dual psychological asymmetry. Humans experience belief-dependent emotions: guilt from disappointing expectations \citep{charness2006promises,sugden_Robert_2000}, reciprocity from perceived intentions \citep{rabin_Incorporating_1993,dufwenberg2004theory}, indignation from violated trust \citep{li_Indignation_2026}. AI optimize programmed objectives without mental states. Existing psychological game theory \citep{battigalli2022belief} assumes symmetric belief-dependent agents and cannot accommodate this heterogeneity.

% Paragraph 2: Empirical Regularities (~175 words)
% Emphatic ending: "partially restores guilt"

Two empirical regularities complicate matters. First, anthropomorphism: humans attribute beliefs, intentions, and expectations to non-human agents \citep{nass2000machines, gray2007dimensions, epley2007seeing}. A meta-analysis of 97 effect sizes shows anthropomorphism increases trust and cooperation in human-AI contexts \citep{blut2021understanding}. Second, attenuation: moral emotions are weaker toward AI than toward humans. Humans feel less guilt exploiting machines \citep{demelo2017people} and less moral outrage when algorithms discriminate \citep{bigman2023people}. Attenuation varies culturally---Japanese participants exhibit guilt toward robots comparable to guilt toward humans, while Western participants show strong attenuation \citep{karpus2025cross}. The magnitude is substantial: Western participants exploit robotic partners at roughly twice the rate of Japanese participants. Attenuation is also design-dependent: AI expressing emotional distress partially restores guilt.

%==============================================================================
% SECTION 2: CORE INNOVATION (ABE CONCEPT)
% Target: 400 words | 3 paragraphs
%==============================================================================

% Paragraph 3: ABE Introduction (~150 words)
% Emphatic ending: "parallel purely human interaction"

We introduce Attributed Belief Equilibrium (ABE) to address this dual asymmetry. ABE extends psychological game theory \citep{geanakoplos1989psychological, battigalli2009dynamic} to games where humans experience psychological payoffs from beliefs about beliefs, while AI optimize programmed objectives. The central insight is that humans attribute mental states to AI: they form beliefs about what AI ``expect'' or ``believe,'' and these attributed beliefs trigger psychological responses---guilt from disappointing attributed expectations, indignation from perceived violations---that parallel purely human interaction.

% Paragraph 4: Attribution and Attenuation Mechanisms (~150 words)
% Emphatic ending: "what the human projects given AI characteristics"

The attribution function captures how humans form beliefs about AI expectations based on three inputs: AI design parameters such as prosociality level, observable signals including interface and behavioral cues, and the human's anthropomorphism tendency. Attenuation parameters scale emotional intensity toward AI, ranging from no attenuation---emotions equal to human-directed---to full attenuation---no emotion toward AI. These attributed beliefs and attenuated emotions enter human utility through standard psychological mechanisms but satisfy different consistency conditions than genuine beliefs: they need not correspond to any actual AI mental state, only to what the human projects given AI characteristics.

% Paragraph 5: Psychological Foundations Connection (~100 words)
% Emphatic ending: "why attribution and attenuation coexist"

This structure reflects mind perception theory \citep{gray2007dimensions}. Humans perceive AI as having agency---capacity to act and form intentions---but lacking experience---capacity to feel and suffer. Agency drives attribution: humans form beliefs about what AI expects. Low perceived experience drives attenuation: moral emotions weaken when the target lacks capacity to suffer. The asymmetry between perceived agency and perceived experience explains why attribution and attenuation coexist.
